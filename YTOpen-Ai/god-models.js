export const god_models = [
  {
    "model": "gpt-3.5-turbo",
    "points": 10,
    "token": 4096
  },
  {
    "model": "gpt-3.5-turbo-16k",
    "points": 10,
    "token": 16384
  },
  {
    "model": "gpt-4",
    "points": 750,
    "token": 8192
  },
  {
    "model": "gpt-4-32k",
    "points": 1200,
    "token": 32768
  },
  {
    "model": "gpt-4-all",
    "points": 1150,
    "token": 32768
  },
  {
    "model": "gpt-4-1106-preview",
    "points": 1,
    "token": 128000
  },
  {
    "model": "gpt-4-0125-preview",
    "points": 1,
    "token": 128000
  },
  {
    "model": "gpt-4-turbo-preview",
    "points": 1,
    "token": 128000
  },
  {
    "model": "claude-1-100k",
    "points": 20,
    "token": 100000
  },
  {
    "model": "claude-1.3",
    "points": 20,
    "token": 7000
  },
  {
    "model": "claude-1.3-100k",
    "points": 20,
    "token": 100000
  },
  {
    "model": "claude-2",
    "points": 20,
    "token": 100000
  },
  {
    "model": "google-palm",
    "points": 10,
    "token": 4096
  },
  {
    "model": "llama-2-7b",
    "points": 10,
    "token": 7000
  },
  {
    "model": "llama-2-13b",
    "points": 10,
    "token": 13000
  },
  {
    "model": "llama-2-70b",
    "points": 10,
    "token": 70000
  },
  {
    "model": "code-llama-7b",
    "points": 10,
    "token": 7000
  },
  {
    "model": "code-llama-13b",
    "points": 10,
    "token": 13000
  },
  {
    "model": "code-llama-34b",
    "points": 10,
    "token": 34000
  },
  {
    "model": "gemini-pro",
    "points": 100,
    "token": 8000
  },
  {
    "model": "qwen-72b",
    "points": 100,
    "token": 72000
  },
  {
    "model": "mixtral-8x7b",
    "points": 50,
    "token": 8000
  },
  {
    "model": "mistral-medium",
    "points": 100,
    "token": 100
  }
]